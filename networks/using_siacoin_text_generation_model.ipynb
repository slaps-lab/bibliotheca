{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab# 5228\n"
     ]
    }
   ],
   "source": [
    "vocab = []\n",
    "\n",
    "with open('../data/reddit/siacoin_vocab.json', 'r') as vocab_input:\n",
    "    vocab = json.loads(vocab_input.read())\n",
    "    \n",
    "vocab_size = len(vocab)\n",
    "word_indices = dict((tk, i) for i, tk in enumerate(vocab))\n",
    "indices_word = dict((i, tk) for i, tk in enumerate(vocab))\n",
    "\n",
    "print('vocab#', vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "siacoin_model = load_model('../data/reddit/models/siacoin_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_sentence(model, seed, iterations = 5):\n",
    "    limit = len(seed)\n",
    "    \n",
    "    sentence = seed.copy()\n",
    "    for iteration in range(0, iterations):\n",
    "        X_new = np.array([sentence[iteration:]])\n",
    "        predicted_class = model.predict_classes(X_new).tolist()\n",
    "        sentence = np.append(sentence, predicted_class)\n",
    "        \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>unlike</td>\n",
       "      <td>poloniex</td>\n",
       "      <td>you</td>\n",
       "      <td>can</td>\n",
       "      <td>set</td>\n",
       "      <td>your</td>\n",
       "      <td>offer</td>\n",
       "      <td>as</td>\n",
       "      <td>a</td>\n",
       "      <td>percentage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>poloniex</td>\n",
       "      <td>you</td>\n",
       "      <td>can</td>\n",
       "      <td>set</td>\n",
       "      <td>your</td>\n",
       "      <td>offer</td>\n",
       "      <td>as</td>\n",
       "      <td>a</td>\n",
       "      <td>percentage</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0         0         1    2    3     4      5      6   7  \\\n",
       "0           0    unlike  poloniex  you  can   set   your  offer  as   \n",
       "1           1  poloniex       you  can  set  your  offer     as   a   \n",
       "\n",
       "            8           9  \n",
       "0           a  percentage  \n",
       "1  percentage          of  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/reddit/siacoin_words_dataset.csv').drop(columns=['target'])\n",
    "\n",
    "df.head(n = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_line(df):\n",
    "    seed_index = np.random.randint(\n",
    "        0,\n",
    "        len(df.index)\n",
    "    )\n",
    "    \n",
    "    seed_text = df.iloc[seed_index].tolist()[1:11]\n",
    "    return np.array([ word_indices[term] for term in seed_text ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['and',\n",
       " 'if',\n",
       " 'you',\n",
       " 'have',\n",
       " 'not',\n",
       " 'given',\n",
       " 'a',\n",
       " 'shot',\n",
       " 'you',\n",
       " 'might',\n",
       " 'find',\n",
       " 'that',\n",
       " 'it',\n",
       " 'resolved',\n",
       " 'some',\n",
       " 'of',\n",
       " 'the',\n",
       " 'bigger',\n",
       " 'issues',\n",
       " 'with',\n",
       " 'a',\n",
       " 'bounty',\n",
       " 'making',\n",
       " 'it',\n",
       " 'but',\n",
       " 'infrastructure',\n",
       " 'decentralized',\n",
       " 'points',\n",
       " 'for',\n",
       " 'the',\n",
       " 'pool',\n",
       " 'can',\n",
       " 'be',\n",
       " 'pulled',\n",
       " 'and',\n",
       " 'handy',\n",
       " 'layer',\n",
       " 'for',\n",
       " 'the',\n",
       " 'peer',\n",
       " 'project',\n",
       " 'nodes',\n",
       " 'and',\n",
       " 'icloud',\n",
       " 'the',\n",
       " 'wallet',\n",
       " 'and',\n",
       " 'internals',\n",
       " 'in',\n",
       " 'a',\n",
       " 'command',\n",
       " 'line',\n",
       " 'api',\n",
       " 'significantly',\n",
       " 'auto',\n",
       " 'segwit',\n",
       " 'video',\n",
       " 'etc',\n",
       " 'by',\n",
       " 'some',\n",
       " 'possibilities',\n",
       " 'to',\n",
       " 'tulips',\n",
       " 'stored',\n",
       " 'into',\n",
       " 'the',\n",
       " 'network',\n",
       " 'and',\n",
       " 'have',\n",
       " 'needed',\n",
       " 'why',\n",
       " 'it',\n",
       " 'are',\n",
       " 'currently',\n",
       " 'working',\n",
       " 'and',\n",
       " 'other',\n",
       " 'because',\n",
       " 'you',\n",
       " 'mean',\n",
       " 'at',\n",
       " 'to',\n",
       " 'sell',\n",
       " 'more',\n",
       " 'done',\n",
       " 'while',\n",
       " 'as',\n",
       " 'have',\n",
       " 'visiting',\n",
       " 'siacoin',\n",
       " 'have',\n",
       " 'sure',\n",
       " 'post',\n",
       " 'editions',\n",
       " 'the',\n",
       " 'road',\n",
       " 'is',\n",
       " 'hacked',\n",
       " 'the',\n",
       " 'full',\n",
       " 'suffering',\n",
       " 'of',\n",
       " 'the',\n",
       " 'union',\n",
       " 'and',\n",
       " 'we',\n",
       " 'described',\n",
       " 'and',\n",
       " 'ethereum',\n",
       " 'release',\n",
       " 'and',\n",
       " 'that',\n",
       " 'we',\n",
       " 'this',\n",
       " 'identified',\n",
       " 'with',\n",
       " 'check',\n",
       " 'and',\n",
       " 'the',\n",
       " 'outlier',\n",
       " 'related',\n",
       " 'to',\n",
       " 'be',\n",
       " 'farms',\n",
       " 'by',\n",
       " 'the',\n",
       " 'chrome',\n",
       " 'explorer',\n",
       " 'or',\n",
       " 'hard',\n",
       " 'and',\n",
       " 'obelisk',\n",
       " 'units',\n",
       " 'are',\n",
       " 'point',\n",
       " 'which',\n",
       " 'and',\n",
       " 'it',\n",
       " 'is',\n",
       " 'understanding',\n",
       " 'the',\n",
       " 'fundamental',\n",
       " 'is',\n",
       " 'wallet',\n",
       " 'questions',\n",
       " 'and',\n",
       " 'a',\n",
       " 'product',\n",
       " 'that',\n",
       " 'looks',\n",
       " 'does',\n",
       " 'not',\n",
       " 'be',\n",
       " 'isnane',\n",
       " 'why',\n",
       " 'as',\n",
       " 'understood',\n",
       " 'easily',\n",
       " 'significantly',\n",
       " 'spread',\n",
       " 'more',\n",
       " 'units',\n",
       " 'the',\n",
       " 'network',\n",
       " 'do',\n",
       " 'not',\n",
       " 'in',\n",
       " 'any',\n",
       " 'backups',\n",
       " 'consuming',\n",
       " 'was',\n",
       " 'offer',\n",
       " 'for',\n",
       " 'upwards',\n",
       " 'serve',\n",
       " 'right',\n",
       " 'rents',\n",
       " 'out',\n",
       " 'that',\n",
       " 'we',\n",
       " 'could',\n",
       " 'money',\n",
       " 'to',\n",
       " 'release',\n",
       " 'deeper',\n",
       " 'asic',\n",
       " 'and',\n",
       " 'days',\n",
       " 'and',\n",
       " 'discord',\n",
       " 'if',\n",
       " 'you',\n",
       " 'helps',\n",
       " 'and',\n",
       " 'the',\n",
       " 'amount',\n",
       " 'of',\n",
       " 'tools',\n",
       " 'like',\n",
       " 'hosts',\n",
       " 'is',\n",
       " 'moderating',\n",
       " 'for',\n",
       " 'most',\n",
       " 'which',\n",
       " 'they',\n",
       " 'siacoin',\n",
       " 'wants',\n",
       " 'to',\n",
       " 'store']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xnew = get_line(df)\n",
    "sentence_of_indices = produce_sentence(siacoin_model, get_line(df), 200)\n",
    "\n",
    "[ indices_word[index] for index in sentence_of_indices ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['on',\n",
       " 'the',\n",
       " 'siacoin',\n",
       " 'team',\n",
       " 'will',\n",
       " 'be',\n",
       " 'helpful',\n",
       " 'to',\n",
       " 'see',\n",
       " 'their',\n",
       " 'current',\n",
       " 'metadata',\n",
       " 'and',\n",
       " 'this',\n",
       " 'data',\n",
       " 'that',\n",
       " 'is',\n",
       " 'looking',\n",
       " 'to',\n",
       " 'announcement',\n",
       " 'but',\n",
       " 'i',\n",
       " 'know',\n",
       " 'to',\n",
       " 'the']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_random_seed(vocab):\n",
    "    m = len(vocab)\n",
    "    return np.random.randint(0, m, 10)\n",
    "    \n",
    "[\n",
    "    indices_word[index]\n",
    "    for index\n",
    "    in produce_sentence(siacoin_model, build_random_seed(vocab), 25)[10:]\n",
    "] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
