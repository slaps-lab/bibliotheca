{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>they</td>\n",
       "      <td>charge</td>\n",
       "      <td>ridiculous</td>\n",
       "      <td>amounts</td>\n",
       "      <td>to</td>\n",
       "      <td>make</td>\n",
       "      <td>small</td>\n",
       "      <td>changes</td>\n",
       "      <td>to</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>charge</td>\n",
       "      <td>ridiculous</td>\n",
       "      <td>amounts</td>\n",
       "      <td>to</td>\n",
       "      <td>make</td>\n",
       "      <td>small</td>\n",
       "      <td>changes</td>\n",
       "      <td>to</td>\n",
       "      <td>the</td>\n",
       "      <td>code</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0       0           1           2        3     4      5        6  \\\n",
       "0           0    they      charge  ridiculous  amounts    to   make    small   \n",
       "1           1  charge  ridiculous     amounts       to  make  small  changes   \n",
       "\n",
       "         7    8     9  \n",
       "0  changes   to   the  \n",
       "1       to  the  code  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/reddit/siacoin_words_dataset_lg.csv').drop(columns=['target'])\n",
    "\n",
    "df.head(n = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### [ 1,2,3,4,5 ] -> sm: [3,4,5], md_sm: [1,2,3,4,5], md: [null], lg: [null]\n",
    "class TextGeneratorModel(object):\n",
    "    def __init__(self, vocab, model, limit, weight):\n",
    "        self.vocab = vocab\n",
    "        self.model = model\n",
    "        self.limit = limit\n",
    "        self.weight = weight\n",
    "        \n",
    "        self.vocab_size = len(self.vocab)\n",
    "        self.word_indices = dict((tk, i) for i, tk in enumerate(self.vocab))\n",
    "        self.indices_word = dict((i, tk) for i, tk in enumerate(self.vocab))\n",
    "        \n",
    "    def get_weight(self):\n",
    "        return self.weight\n",
    "    \n",
    "    def get_line(self, sentence):\n",
    "        return np.array([ \n",
    "            self.word_indices[token]\n",
    "            for token\n",
    "            in sentence\n",
    "        ])\n",
    "    \n",
    "    def predict_next(self, sentence: list) -> int:\n",
    "        ## translate it,\n",
    "        line = self.get_line(sentence)\n",
    "    \n",
    "        ## start: 0, end: len -> [limit: len]\n",
    "        start = len(sentence) - self.limit\n",
    "        if start < 0:\n",
    "            return -1\n",
    "        \n",
    "        X_new = np.array([line[start:]])\n",
    "        predicted_class = self.model.predict_classes(X_new).tolist()\n",
    "        \n",
    "        index = predicted_class[0]\n",
    "        return (index, self.indices_word[index])\n",
    "    \n",
    "class TextGeneratorEnsemble(object):\n",
    "    def __init__(self, generators):\n",
    "        self.generators = generators\n",
    "        \n",
    "    def predict_next(self, sentence):\n",
    "        weights = []\n",
    "        results = []\n",
    "        \n",
    "        for generator in self.generators:\n",
    "            predicted_class = generator.predict_next(sentence)\n",
    "            if predicted_class[0] == -1:\n",
    "                continue\n",
    "            \n",
    "            results.append(predicted_class)\n",
    "            weights.append(generator.get_weight())\n",
    "            \n",
    "        if len(results) == 0:\n",
    "            return -1\n",
    "        \n",
    "        s = np.sum(weights)\n",
    "        index = np.random.choice(\n",
    "            list(range(len(results))),\n",
    "            1,\n",
    "            p = weights / s\n",
    "        )[0]\n",
    "        \n",
    "        return results[index][1], results\n",
    "    \n",
    "class TextGenerator(object):\n",
    "    def __init__(self, ensemble, sentence):\n",
    "        self.ensemble = ensemble\n",
    "        self.sentence = sentence\n",
    "        \n",
    "    def get_next_word(self):\n",
    "        next_token, results = ensemble.predict_next(self.sentence)\n",
    "        self.sentence = np.append(self.sentence, next_token)\n",
    "        return next_token, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "models = [\n",
    "    { 'type': '_sm', 'limit': 3, 'weight': 1  },\n",
    "    { 'type': '_sm_md', 'limit': 5, 'weight': 1 },\n",
    "    { 'type': '_md', 'limit': 7, 'weight': 3 },\n",
    "    { 'type': '_lg', 'limit': 10, 'weight': 1 },\n",
    "]\n",
    "\n",
    "text_generators = []\n",
    "for model in models:\n",
    "    key = model['type']\n",
    "    \n",
    "    vocab = []\n",
    "    with open(f'../data/reddit/models/siacoin_vocab{key}.json', 'r') as vocab_input:\n",
    "        vocab = json.loads(vocab_input.read())\n",
    "    \n",
    "    template = f'../data/reddit/models/siacoin_model{key}.h5'\n",
    "    siacoin_model = load_model(template)\n",
    "    siacoin_text_generator = TextGeneratorModel(\n",
    "        vocab,\n",
    "        siacoin_model,\n",
    "        model['limit'],\n",
    "        model['weight']\n",
    "    )\n",
    "    \n",
    "    text_generators.append(siacoin_text_generator)\n",
    "\n",
    "ensemble = TextGeneratorEnsemble(text_generators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(899)\n",
    "\n",
    "limit = 10\n",
    "seed_index = np.random.randint(\n",
    "    0,\n",
    "    len(df.index)\n",
    ")\n",
    "\n",
    "data_frame = df.iloc[seed_index]\n",
    "line = data_frame.tolist()[1:limit+1]\n",
    "\n",
    "text_generator = TextGenerator(ensemble, line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['what',\n",
       " 'are',\n",
       " 'my',\n",
       " 'current',\n",
       " 'values',\n",
       " 'for',\n",
       " 'host',\n",
       " 'config',\n",
       " 'besides',\n",
       " 'looking']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ tk for tk in line]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "into - ['into', 'and', 'into', 'into']\n",
      "the - ['the', 'the', 'the', 'the']\n",
      "json - ['json', 'developing', 'json', 'json']\n",
      "on - ['on', 'on', 'on', 'on']\n",
      "disk - ['disk', 'disk', 'disk', 'value']\n",
      "which - ['which', 'which', 'which', 'week']\n",
      "will - ['are', 'are', 'are', 'will']\n",
      "i - ['be', 'facilitate', 'not', 'i']\n",
      "just - ['never', 'be', 'just', 'do']\n",
      "remove - ['be', 'adjustments', 'remove', 'a']\n",
      "yet - ['my', 'another', 'this', 'yet']\n",
      "from - ['that', 'to', 'from', 'is']\n",
      "my - ['your', 'the', 'my', 'there']\n",
      "role - ['time', 'computer', 'role', 'of']\n",
      "and - ['streaming', 'in', 'and', 'what']\n",
      "let - ['writing', 'still', 'let', 'the']\n",
      "us - ['is', 'us', 'us', 'siacoin']\n",
      "talk - ['know', 'talk', 'see', 'to']\n",
      "for - ['about', 'down', 'to', 'for']\n",
      "proofs - ['a', 'proofs', 'the', 'their']\n",
      "of - ['with', 'of', 'of', 'through']\n",
      "monetizing - ['blown', 'hundreds', 'monetizing', 'the']\n",
      "account - ['have', 'a', 'coins', 'account']\n",
      "pricing - ['out', 'and', 'pricing', 'over']\n",
      "to - ['as', 'it', 'to', 'and']\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 25):\n",
    "    next_token, choices = text_generator.get_next_word()\n",
    "    print(\n",
    "        next_token, '-', [ tk for i, tk in choices ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
