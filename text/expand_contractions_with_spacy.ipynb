{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_text = 'I can\\'t, cant, cannot, won\\'t, wont do it!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "from spacy.tokens import Doc\n",
    "from spacy.language import Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%html\n",
    "\n",
    "<h3>Control Group:</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_1 = spacy.load('en_core_web_sm') ## no expansion, control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_only = nlp_1(example_text)\n",
    "\n",
    "hash_lookup_1 = defaultdict(int)\n",
    "for tk in left_only:\n",
    "    hash_lookup_1[tk.text] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%html\n",
    "\n",
    "<h3>Test Group:</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_2 = spacy.load('en_core_web_sm') ## expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_contractions(text: str) -> str:\n",
    "    \n",
    "    ## https://en.wikipedia.org/wiki/Wikipedia:List_of_English_contractions\n",
    "    \n",
    "    flags = re.IGNORECASE | re.MULTILINE\n",
    "    \n",
    "    text = re.sub(r'`', \"'\", text, flags = flags)\n",
    "    \n",
    "    ## starts / ends with '\n",
    "    text = re.sub(\n",
    "        r\"(\\s|^)'(aight|cause)(\\s|$)\",\n",
    "        '\\g<1>\\g<2>\\g<3>',\n",
    "        text, flags = flags\n",
    "    )\n",
    "    \n",
    "    text = re.sub(\n",
    "        r\"(\\s|^)'t(was|is)(\\s|$)\", r'\\g<1>it \\g<2>\\g<3>',\n",
    "        text,\n",
    "        flags = flags\n",
    "    )\n",
    "    \n",
    "    text = re.sub(\n",
    "        r\"(\\s|^)ol'(\\s|$)\",\n",
    "        '\\g<1>old\\g<2>',\n",
    "        text, flags = flags\n",
    "    )\n",
    "    \n",
    "    ## expand words without '\n",
    "    text = re.sub(r\"\\b(aight)\\b\", 'alright', text, flags = flags)\n",
    "    text = re.sub(r'\\bcause\\b', 'because', text, flags = flags)\n",
    "    text = re.sub(r'\\b(finna|gonna)\\b', 'going to', text, flags = flags)\n",
    "    text = re.sub(r'\\bgimme\\b', 'give me', text, flags = flags)\n",
    "    text = re.sub(r\"\\bgive'n\\b\", 'given', text, flags = flags)\n",
    "    text = re.sub(r\"\\bhowdy\\b\", 'how do you do', text, flags = flags)\n",
    "    text = re.sub(r\"\\bgotta\\b\", 'got to', text, flags = flags)\n",
    "    text = re.sub(r\"\\binnit\\b\", 'is it not', text, flags = flags)\n",
    "    text = re.sub(r\"\\b(can)(not)\\b\", r'\\g<1> \\g<2>', text, flags = flags)\n",
    "    text = re.sub(r\"\\bwanna\\b\", 'want to', text, flags = flags)\n",
    "    text = re.sub(r\"\\bmethinks\\b\", 'me thinks', text, flags = flags)\n",
    "    \n",
    "    ## one offs,\n",
    "    text = re.sub(r\"\\bo'er\\b\", r'over', text, flags = flags)\n",
    "    text = re.sub(r\"\\bne'er\\b\", r'never', text, flags = flags)\n",
    "    text = re.sub(r\"\\bo'?clock\\b\", 'of the clock', text, flags = flags)\n",
    "    text = re.sub(r\"\\bma'am\\b\", 'madam', text, flags = flags)\n",
    "    text = re.sub(r\"\\bgiv'n\\b\", 'given', text, flags = flags)\n",
    "    text = re.sub(r\"\\be'er\\b\", 'ever', text, flags = flags)\n",
    "    text = re.sub(r\"\\bd'ye\\b\", 'do you', text, flags = flags)\n",
    "    text = re.sub(r\"\\be'er\\b\", 'ever', text, flags = flags)\n",
    "    text = re.sub(r\"\\bd'ye\\b\", 'do you', text, flags = flags)\n",
    "    text = re.sub(r\"\\bg'?day\\b\", 'good day', text, flags = flags)\n",
    "    text = re.sub(r\"\\b(ain|amn)'?t\\b\", 'am not', text, flags = flags)\n",
    "    text = re.sub(r\"\\b(are|can)'?t\\b\", r'\\g<1> not', text, flags = flags)\n",
    "    text = re.sub(r\"\\b(let)'?s\\b\", r'\\g<1> us', text, flags = flags)\n",
    "    \n",
    "    ## major expansions involving smaller,\n",
    "    text = re.sub(r\"\\by'all'dn't've'd\\b\", 'you all would not have had', text, flags = flags)\n",
    "    text = re.sub(r\"\\by'all're\\b\", 'you all are', text, flags = flags)\n",
    "    text = re.sub(r\"\\by'all'd've\\b\", 'you all would have', text, flags = flags)\n",
    "    text = re.sub(r\"(\\s)y'all(\\s)\", r'\\g<1>you all\\g<2>', text, flags = flags)\n",
    "    \n",
    "    ## minor,\n",
    "    text = re.sub(r\"\\b(won)'?t\\b\", 'will not', text, flags = flags)\n",
    "    text = re.sub(r\"\\bhe'd\\b\", 'he had', text, flags = flags)\n",
    "\n",
    "    ## major,\n",
    "    text = re.sub(r\"\\b(I|we|who)'?d'?ve\\b\", r'\\g<1> would have', text, flags = flags)\n",
    "    text = re.sub(r\"\\b(could|would|must|should|would)n'?t'?ve\\b\", r'\\g<1> not have', text, flags = flags)\n",
    "    text = re.sub(r\"\\b(he)'?dn'?t'?ve'?d\\b\", r'\\g<1> would not have had', text, flags = flags)\n",
    "    text = re.sub(r\"\\b(daren|daresn|dasn)'?t\", 'dare not', text, flags = flags)\n",
    "    text = re.sub(r\"\\b(he|how|i|it|she|that|there|these|they|we|what|where|which|who|you)'?ll\\b\", r'\\g<1> will', text, flags = flags)\n",
    "    text = re.sub(r\"\\b(everybody|everyone|he|how|it|she|somebody|someone|something|that|there|this|what|when|where|which|who|why)'?s\\b\", r'\\g<1> is', text, flags = flags)\n",
    "    text = re.sub(r\"\\b(I)'?m'a\\b\", r'\\g<1> am about to', text, flags = flags)\n",
    "    text = re.sub(r\"\\b(I)'?m'o\\b\", r'\\g<1> am going to', text, flags = flags)\n",
    "    text = re.sub(r\"\\b(I)'?m\\b\", r'\\g<1> am', text, flags = flags)\n",
    "    text = re.sub(r\"\\bshan't\\b\", 'shall not', text, flags = flags)\n",
    "    text = re.sub(r\"\\b(are|could|did|does|do|go|had|has|have|is|may|might|must|need|ought|shall|should|was|were|would)n'?t\\b\", r'\\g<1> not', text, flags = flags)\n",
    "    text = re.sub(r\"\\b(could|had|he|i|may|might|must|should|these|they|those|to|we|what|where|which|who|would|you)'?ve\\b\", r'\\g<1> have', text, flags = flags)\n",
    "    text = re.sub(r\"\\b(how|so|that|there|these|they|those|we|what|where|which|who|why|you)'?re\\b\", r'\\g<1> are', text, flags = flags)\n",
    "    text = re.sub(r\"\\b(I|it|she|that|there|they|we|which|you)'?d\\b\", r'\\g<1> had', text, flags = flags)\n",
    "    text = re.sub(r\"\\b(how|what|where|who|why)'?d\\b\", r'\\g<1> did', text, flags = flags)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = \"\"\"\n",
    " 'aight = alright\n",
    " ain't = am not\n",
    " amn't = am not\n",
    " aren't = are not\n",
    " can't = can not\n",
    " 'cause = because\n",
    " could've = could have\n",
    " couldn't = could not\n",
    " couldn't've = could not have\n",
    " daren't = dare not\n",
    " daresn't = dare not\n",
    " dasn't = dare not\n",
    " didn't = did not\n",
    " doesn't = does not\n",
    " don't = do not\n",
    " d'ye = do you\n",
    " e'er = ever\n",
    " everybody's = everybody is\n",
    " everyone's = everyone is\n",
    " finna = going to\n",
    " g'day = good day\n",
    " gimme = give me\n",
    " giv'n = given\n",
    " gonna = going to\n",
    " gon't = go not\n",
    " gotta = got to\n",
    " hadn't = had not\n",
    " had've = had have\n",
    " hasn't = has not\n",
    " haven't = have not\n",
    " he'd = he had\n",
    " he'dn't've'd = he would not have had\n",
    " he'll = he will\n",
    " he's = he is\n",
    " he've = he have\n",
    " how'd = how did\n",
    " howdy = how do you do\n",
    " how'll = how will\n",
    " how're = how are\n",
    " how's = how is\n",
    " I'd = I had\n",
    " I'd've = I would have\n",
    " I'll = I will\n",
    " I'm = I am\n",
    " I'm'a = I am about to\n",
    " I'm'o = I am going to\n",
    " innit = is it not\n",
    " I've = I have\n",
    " isn't = is not\n",
    " it'd = it had\n",
    " it'll = it will\n",
    " it's = it is\n",
    " let's = let us\n",
    " ma'am = madam\n",
    " mayn't = may not\n",
    " may've = may have\n",
    " methinks = me thinks\n",
    " mightn't = might not\n",
    " might've = might have\n",
    " mustn't = must not\n",
    " mustn't've = must not have\n",
    " must've = must have\n",
    " needn't = need not\n",
    " ne'er = never\n",
    " o'clock = of the clock\n",
    " o'er = over\n",
    " ol' = old\n",
    " oughtn't = ought not\n",
    " shalln't = shall not\n",
    " shan't = shall not\n",
    " she'd = she had\n",
    " she'll = she will\n",
    " she's = she is\n",
    " should've = should have\n",
    " shouldn't = should not\n",
    " shouldn't've = should not have\n",
    " somebody's = somebody is\n",
    " someone's = someone is\n",
    " something's = something is\n",
    " so're = so are\n",
    " that'll = that will\n",
    " that're = that are\n",
    " that's = that is\n",
    " that'd = that had\n",
    " there'd = there had\n",
    " there'll = there will\n",
    " there're = there are\n",
    " there's = there is\n",
    " these're = these are\n",
    " these've = these have\n",
    " they'd = they had\n",
    " they'll = they will\n",
    " they're = they are\n",
    " they've = they have\n",
    " this's = this is\n",
    " those're = those are\n",
    " those've = those have\n",
    " 'tis = it is\n",
    " to've = to have\n",
    " 'twas = it was\n",
    " wanna = want to\n",
    " wasn't = was not\n",
    " we'd = we had\n",
    " we'd've = we would have\n",
    " we'll = we will\n",
    " we're = we are\n",
    " we've = we have\n",
    " weren't = were not\n",
    " what'd = what did\n",
    " what'll = what will\n",
    " what're = what are\n",
    " what's = what is\n",
    " what've = what have\n",
    " when's = when is\n",
    " where'd = where did\n",
    " where'll = where will\n",
    " where're = where are\n",
    " where's = where is\n",
    " where've = where have\n",
    " which'd = which had\n",
    " which'll = which will\n",
    " which're = which are\n",
    " which's = which is\n",
    " which've = which have\n",
    " who'd = who did\n",
    " who'd've = who would have\n",
    " who'll = who will\n",
    " who're = who are\n",
    " who's = who is\n",
    " who've = who have\n",
    " why'd = why did\n",
    " why're = why are\n",
    " why's = why is\n",
    " won't = will not\n",
    " would've = would have\n",
    " wouldn't = would not\n",
    " wouldn't've = would not have\n",
    " y'all = you all\n",
    " y'all'd've = you all would have\n",
    " y'all'dn't've'd = you all would not have had\n",
    " y'all're = you all are\n",
    " you'd = you had\n",
    " you'll = you will\n",
    " you're = you are\n",
    " you've = you have\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = expand_contractions(test_text).split('\\n')\n",
    "\n",
    "for row in ( row for row in rows if row != ''):\n",
    "    left, right = list(map(lambda r: r.strip(), row.split(' = ')))\n",
    "    \n",
    "    assert left == right, f\"{left} = {right}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I can not, can not, can not, will not, will not do it!'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expand_contractions(example_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExpandContractionsComponent(object):\n",
    "    name = \"expand_contractions\"\n",
    "\n",
    "    nlp: Language\n",
    "\n",
    "    def __init__(self, nlp: Language):\n",
    "        self.nlp = nlp\n",
    "\n",
    "    def __call__(self, doc: Doc) -> Doc:\n",
    "        text = doc.text\n",
    "        return self.nlp.make_doc(expand_contractions(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tagger', <spacy.pipeline.pipes.Tagger at 0x106e16320>),\n",
       " ('parser', <spacy.pipeline.pipes.DependencyParser at 0x105e8ee28>),\n",
       " ('ner', <spacy.pipeline.pipes.EntityRecognizer at 0x105e8ee88>)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_2.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_2.add_pipe(\n",
    "    ExpandContractionsComponent(nlp_2),\n",
    "    before = 'tagger'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('expand_contractions',\n",
       "  <__main__.ExpandContractionsComponent at 0x1259eb8d0>),\n",
       " ('tagger', <spacy.pipeline.pipes.Tagger at 0x106e16320>),\n",
       " ('parser', <spacy.pipeline.pipes.DependencyParser at 0x105e8ee28>),\n",
       " ('ner', <spacy.pipeline.pipes.EntityRecognizer at 0x105e8ee88>)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_2.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp_2('I can\\'t, cant, cannot, won\\'t, wont do it!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "hash_lookup_2 = defaultdict(int)\n",
    "for tk in doc:\n",
    "    hash_lookup_2[tk.text] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I can't, cant, cannot, won't, wont do it!\n"
     ]
    }
   ],
   "source": [
    "print(example_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%html\n",
    "\n",
    "<h3>Results:</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'I': 1, 'ca': 2, \"n't\": 2, ',': 4, 'nt': 2, 'can': 1, 'not': 1, 'wo': 2, 'do': 1, 'it': 1, '!': 1}\n"
     ]
    }
   ],
   "source": [
    "## control group,\n",
    "print(dict(hash_lookup_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'I': 1, 'can': 3, 'not': 5, ',': 4, 'will': 2, 'do': 1, 'it': 1, '!': 1}\n"
     ]
    }
   ],
   "source": [
    "## test group,\n",
    "print(dict(hash_lookup_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
